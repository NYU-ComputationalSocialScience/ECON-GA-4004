{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear State Space Models\n",
    "\n",
    "\n",
    "<a id='index-0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "> “We may regard the present state of the universe as the effect of its past and the cause of its future” – Marquis de Laplace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This lecture introduces the **linear state space** dynamic system.\n",
    "\n",
    "The linear state space system is a generalization of the scalar AR(1) process [we studied before](https://python.quantecon.org/ar1_processes.html).\n",
    "\n",
    "This model is a workhorse that carries a powerful theory of prediction.\n",
    "\n",
    "Its many applications include:\n",
    "\n",
    "- representing dynamics of higher-order linear systems  \n",
    "- predicting the position of a system $ j $ steps into the future  \n",
    "- predicting a geometric sum of future values of a variable like  \n",
    "  - non-financial income  \n",
    "  - dividends on a stock  \n",
    "  - the money supply  \n",
    "  - a government deficit or surplus, etc.  \n",
    "\n",
    "Let’s start with some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from quantecon import LinearStateSpace\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 5)  #set default figure size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Linear State Space Model\n",
    "\n",
    "\n",
    "<a id='index-1'></a>\n",
    "The objects in play are:\n",
    "\n",
    "- An $ n \\times 1 $ vector $ x_t $ denoting the **state** at time $ t = 0, 1, 2, \\ldots $.  \n",
    "- An IID sequence of $ m \\times 1 $ random vectors $ w_t \\sim N(0,I) $.  \n",
    "- A $ k \\times 1 $ vector $ y_t $ of **observations** at time $ t = 0, 1, 2, \\ldots $.  \n",
    "- An $ n \\times n $ matrix $ A $  called the **transition matrix**.  \n",
    "- An $ n \\times m $ matrix $ C $  called the **volatility matrix**.  \n",
    "- A $ k \\times n $ matrix $ G $ sometimes called the **output matrix**.  \n",
    "\n",
    "\n",
    "Here is the linear state-space system\n",
    "\n",
    "\n",
    "<a id='equation-st-space-rep'></a>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    x_{t+1} & =  A x_t + C w_{t+1}   \\\\\n",
    "    y_t &  =  G x_t \\nonumber \\\\\n",
    "    x_0 & \\sim N(\\mu_0, \\Sigma_0) \\nonumber\n",
    "\\end{aligned} \\tag{1}\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='lss-pgs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Primitives\n",
    "\n",
    "The primitives of the model are\n",
    "\n",
    "1. the matrices $ A, C, G $  \n",
    "1. shock distribution, which we have specialized to $ N(0,I) $  \n",
    "1. the distribution of the initial condition $ x_0 $, which we have set to $ N(\\mu_0, \\Sigma_0) $  \n",
    "\n",
    "\n",
    "Given $ A, C, G $ and draws of $ x_0 $ and $ w_1, w_2, \\ldots $, the\n",
    "model [(14.1)](#equation-st-space-rep) pins down the values of the sequences $ \\{x_t\\} $ and $ \\{y_t\\} $.\n",
    "\n",
    "Even without these draws, the primitives 1–3 pin down the *probability distributions* of $ \\{x_t\\} $ and $ \\{y_t\\} $.\n",
    "\n",
    "Later we’ll see how to compute these distributions and their moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Examples\n",
    "\n",
    "By appropriate choice of the primitives, a variety of dynamics can be represented in terms of the linear state space model.\n",
    "\n",
    "The following examples help to highlight this point.\n",
    "\n",
    "They also illustrate the wise dictum *finding the state is an art*.\n",
    "\n",
    "\n",
    "<a id='lss-sode'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Second-order Difference Equation\n",
    "\n",
    "Let $ \\{y_t\\} $ be a deterministic sequence that satisfies\n",
    "\n",
    "\n",
    "<a id='equation-st-ex-1'></a>\n",
    "$$\n",
    "y_{t+1} =  \\phi_0 + \\phi_1 y_t + \\phi_2 y_{t-1}\n",
    "\\quad \\text{s.t.} \\quad\n",
    "y_0, y_{-1} \\text{ given} \\tag{2}\n",
    "$$\n",
    "\n",
    "To map [(14.2)](#equation-st-ex-1) into our state space system [(14.1)](#equation-st-space-rep), we set\n",
    "\n",
    "$$\n",
    "x_t=\n",
    "\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    y_t \\\\\n",
    "    y_{t-1}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "A = \\begin{bmatrix}\n",
    "          1 & 0 & 0 \\\\\n",
    "          \\phi_0 & \\phi_1 & \\phi_2  \\\\\n",
    "          0 & 1 & 0\n",
    "    \\end{bmatrix}\n",
    "\\qquad\n",
    "C= \\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    0 \\\\\n",
    "    0\n",
    "    \\end{bmatrix}\n",
    "\\qquad\n",
    "G = \\begin{bmatrix} 0 & 1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "You can confirm that under these definitions, [(14.1)](#equation-st-space-rep) and [(14.2)](#equation-st-ex-1) agree.\n",
    "\n",
    "The next figure shows the dynamics of this process when $ \\phi_0 = 1.1, \\phi_1=0.8, \\phi_2 = -0.8, y_0 = y_{-1} = 1 $.\n",
    "\n",
    "\n",
    "<a id='lss-sode-fig'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_lss(A,\n",
    "         C,\n",
    "         G,\n",
    "         n=3,\n",
    "         ts_length=50):\n",
    "\n",
    "    ar = LinearStateSpace(A, C, G, mu_0=np.ones(n))\n",
    "    x, y = ar.simulate(ts_length)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    y = y.flatten()\n",
    "    ax.plot(y, 'b-', lw=2, alpha=0.7)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('time', fontsize=12)\n",
    "    ax.set_ylabel('$y_t$', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ϕ_0, ϕ_1, ϕ_2 = 1.1, 0.8, -0.8\n",
    "\n",
    "A = [[1,     0,     0  ],\n",
    "     [ϕ_0,   ϕ_1,   ϕ_2],\n",
    "     [0,     1,     0  ]]\n",
    "C = np.zeros((3, 1))\n",
    "G = [0, 1, 0]\n",
    "\n",
    "plot_lss(A, C, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Univariate Autoregressive Processes\n",
    "\n",
    "\n",
    "<a id='index-3'></a>\n",
    "We can use [(14.1)](#equation-st-space-rep) to represent the model\n",
    "\n",
    "\n",
    "<a id='equation-eq-ar-rep'></a>\n",
    "$$\n",
    "y_{t+1} = \\phi_1 y_{t} + \\phi_2 y_{t-1} + \\phi_3 y_{t-2} + \\phi_4  y_{t-3} + \\sigma w_{t+1} \\tag{3}\n",
    "$$\n",
    "\n",
    "where $ \\{w_t\\} $ is IID and standard normal.\n",
    "\n",
    "To put this in the linear state space format we take $ x_t = \\begin{bmatrix} y_t & y_{t-1} &  y_{t-2} &  y_{t-3} \\end{bmatrix}' $ and\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "    \\phi_1 & \\phi_2 & \\phi_3 & \\phi_4 \\\\\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    0 & 1 & 0 & 0 \\\\\n",
    "    0 & 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "C = \\begin{bmatrix}\n",
    "        \\sigma \\\\\n",
    "        0 \\\\\n",
    "        0 \\\\\n",
    "        0\n",
    "    \\end{bmatrix}\n",
    "\\qquad\n",
    " G = \\begin{bmatrix}\n",
    "         1 & 0  & 0 & 0\n",
    "     \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The matrix $ A $ has the form of the *companion matrix* to the vector\n",
    "$ \\begin{bmatrix}\\phi_1 &  \\phi_2 & \\phi_3 & \\phi_4 \\end{bmatrix} $.\n",
    "\n",
    "The next figure shows the dynamics of this process when\n",
    "\n",
    "$$\n",
    "\\phi_1 = 0.5, \\phi_2 = -0.2, \\phi_3 = 0, \\phi_4 = 0.5, \\sigma = 0.2, y_0 = y_{-1} = y_{-2} =\n",
    "y_{-3} = 1\n",
    "$$\n",
    "\n",
    "\n",
    "<a id='lss-uap-fig'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ϕ_1, ϕ_2, ϕ_3, ϕ_4 = 0.5, -0.2, 0, 0.5\n",
    "σ = 0.2\n",
    "\n",
    "A_1 = [[ϕ_1,   ϕ_2,   ϕ_3,   ϕ_4],\n",
    "       [1,     0,     0,     0  ],\n",
    "       [0,     1,     0,     0  ],\n",
    "       [0,     0,     1,     0  ]]\n",
    "\n",
    "C_1 = [[σ],\n",
    "       [0],\n",
    "       [0],\n",
    "       [0]]\n",
    "\n",
    "G_1 = [1, 0, 0, 0]\n",
    "\n",
    "plot_lss(A_1, C_1, G_1, n=4, ts_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Seasonals\n",
    "\n",
    "\n",
    "<a id='index-5'></a>\n",
    "We can use [(14.1)](#equation-st-space-rep) to represent\n",
    "\n",
    "1. the *deterministic seasonal* $ y_t = y_{t-4} $  \n",
    "1. the *indeterministic seasonal* $ y_t = \\phi_4 y_{t-4} + w_t $  \n",
    "\n",
    "\n",
    "In fact, both are special cases of [(14.3)](#equation-eq-ar-rep).\n",
    "\n",
    "With the deterministic seasonal, the transition matrix becomes\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "        0 & 0 & 0 & 1 \\\\\n",
    "        1 & 0 & 0 & 0 \\\\\n",
    "        0 & 1 & 0 & 0 \\\\\n",
    "        0 & 0 & 1 & 0\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It is easy to check that $ A^4 = I $, which implies that $ x_t $ is strictly periodic with period 4:<sup><a href=#foot1 id=foot1-link>[1]</a></sup>\n",
    "\n",
    "$$\n",
    "x_{t+4} = x_t\n",
    "$$\n",
    "\n",
    "Such an $ x_t $ process can be used to model deterministic seasonals in quarterly time series.\n",
    "\n",
    "The *indeterministic* seasonal produces recurrent, but aperiodic, seasonal fluctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Time Trends\n",
    "\n",
    "\n",
    "<a id='index-6'></a>\n",
    "The model $ y_t = a t + b $ is known as a *linear time trend*.\n",
    "\n",
    "We can represent this model in the linear state space form by taking\n",
    "\n",
    "\n",
    "<a id='equation-lss-ltt'></a>\n",
    "$$\n",
    "A\n",
    "= \\begin{bmatrix}\n",
    "    1 & 1  \\\\\n",
    "    0 & 1\n",
    "  \\end{bmatrix}\n",
    "\\qquad\n",
    "C\n",
    "= \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        0\n",
    "  \\end{bmatrix}\n",
    "\\qquad\n",
    "G\n",
    "= \\begin{bmatrix}\n",
    "        a & b\n",
    "  \\end{bmatrix} \\tag{4}\n",
    "$$\n",
    "\n",
    "and starting at initial condition $ x_0 = \\begin{bmatrix} 0 & 1\\end{bmatrix}' $.\n",
    "\n",
    "In fact, it’s possible to use the state-space system to represent polynomial trends of any order.\n",
    "\n",
    "For instance, we can represent the model $ y_t = a t^2 + bt + c $ in the linear state space form by taking\n",
    "\n",
    "$$\n",
    "A\n",
    "= \\begin{bmatrix}\n",
    "    1 & 1 & 0 \\\\\n",
    "    0 & 1 & 1 \\\\\n",
    "    0 & 0 & 1\n",
    "  \\end{bmatrix}\n",
    "\\qquad\n",
    "C\n",
    "= \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        0 \\\\\n",
    "        0\n",
    "  \\end{bmatrix}\n",
    "\\qquad\n",
    "G\n",
    "= \\begin{bmatrix}\n",
    "        2a & a + b & c\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and starting at initial condition $ x_0 = \\begin{bmatrix} 0 & 0 & 1 \\end{bmatrix}' $.\n",
    "\n",
    "It follows that\n",
    "\n",
    "$$\n",
    "A^t =\n",
    "\\begin{bmatrix}\n",
    " 1 & t & t(t-1)/2 \\\\\n",
    " 0 & 1 & t \\\\\n",
    " 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then $ x_t^\\prime = \\begin{bmatrix} t(t-1)/2 &t & 1 \\end{bmatrix} $. You can now confirm that $ y_t = G x_t $ has the correct form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributions and Moments\n",
    "\n",
    "\n",
    "<a id='index-9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unconditional Moments\n",
    "\n",
    "Using [(14.1)](#equation-st-space-rep), it’s easy to obtain expressions for the\n",
    "(unconditional) means of $ x_t $ and $ y_t $.\n",
    "\n",
    "We’ll explain what *unconditional* and *conditional* mean soon.\n",
    "\n",
    "Letting $ \\mu_t := \\mathbb{E} [x_t] $ and using linearity of expectations, we\n",
    "find that\n",
    "\n",
    "\n",
    "<a id='equation-lss-mut-linear-models'></a>\n",
    "$$\n",
    "\\mu_{t+1} = A \\mu_t\n",
    "\\quad \\text{with} \\quad \\mu_0 \\text{ given} \\tag{6}\n",
    "$$\n",
    "\n",
    "Here $ \\mu_0 $ is a primitive given in [(14.1)](#equation-st-space-rep).\n",
    "\n",
    "The variance-covariance matrix of $ x_t $ is $ \\Sigma_t := \\mathbb{E} [ (x_t - \\mu_t) (x_t - \\mu_t)'] $.\n",
    "\n",
    "Using $ x_{t+1} - \\mu_{t+1} = A (x_t - \\mu_t) + C w_{t+1} $, we can\n",
    "determine this matrix recursively via\n",
    "\n",
    "\n",
    "<a id='equation-eqsigmalaw-linear-models'></a>\n",
    "$$\n",
    "\\Sigma_{t+1}  = A \\Sigma_t A' + C C'\n",
    "\\quad \\text{with} \\quad \\Sigma_0 \\text{ given} \\tag{7}\n",
    "$$\n",
    "\n",
    "As with $ \\mu_0 $, the matrix $ \\Sigma_0 $ is a primitive given in [(14.1)](#equation-st-space-rep).\n",
    "\n",
    "As a matter of terminology, we will sometimes call\n",
    "\n",
    "- $ \\mu_t $ the *unconditional mean*  of $ x_t $  \n",
    "- $ \\Sigma_t $ the *unconditional variance-covariance matrix*  of $ x_t $  \n",
    "\n",
    "\n",
    "This is to distinguish $ \\mu_t $ and $ \\Sigma_t $ from related objects that use conditioning\n",
    "information, to be defined below.\n",
    "\n",
    "However, you should be aware that these “unconditional” moments do depend on\n",
    "the initial distribution $ N(\\mu_0, \\Sigma_0) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Moments of the Observations\n",
    "\n",
    "Using linearity of expectations again we have\n",
    "\n",
    "\n",
    "<a id='equation-lss-umy'></a>\n",
    "$$\n",
    "\\mathbb{E} [y_t] = \\mathbb{E} [G x_t] = G \\mu_t \\tag{8}\n",
    "$$\n",
    "\n",
    "The variance-covariance matrix of $ y_t $ is easily shown to be\n",
    "\n",
    "\n",
    "<a id='equation-lss-uvy'></a>\n",
    "$$\n",
    "\\textrm{Var} [y_t] = \\textrm{Var} [G x_t] = G \\Sigma_t G' \\tag{9}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distributions\n",
    "\n",
    "\n",
    "<a id='index-10'></a>\n",
    "In general, knowing the mean and variance-covariance matrix of a random vector\n",
    "is not quite as good as knowing the full distribution.\n",
    "\n",
    "However, there are some situations where these moments alone tell us all we\n",
    "need to know.\n",
    "\n",
    "These are situations in which the mean vector and covariance matrix are **sufficient statistics** for the population distribution.\n",
    "\n",
    "(Sufficient statistics form a list of objects that characterize a population distribution)\n",
    "\n",
    "One such situation is when the vector in question is Gaussian (i.e., normally\n",
    "distributed).\n",
    "\n",
    "This is the case here, given\n",
    "\n",
    "1. our Gaussian assumptions on the primitives  \n",
    "1. the fact that normality is preserved under linear operations  \n",
    "\n",
    "\n",
    "In fact, it’s [well-known](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Affine_transformation) that\n",
    "\n",
    "\n",
    "<a id='equation-lss-glig'></a>\n",
    "$$\n",
    "u \\sim N(\\bar u, S)\n",
    "\\quad \\text{and} \\quad\n",
    "v = a + B u\n",
    "\\implies\n",
    "v \\sim N(a + B \\bar u, B S B') \\tag{10}\n",
    "$$\n",
    "\n",
    "In particular, given our Gaussian assumptions on the primitives and the\n",
    "linearity of [(14.1)](#equation-st-space-rep) we can see immediately that  both $ x_t $ and\n",
    "$ y_t $ are  Gaussian for all $ t \\geq 0 $ <sup><a href=#fn-ag id=fn-ag-link>[2]</a></sup>.\n",
    "\n",
    "Since $ x_t $ is Gaussian, to find the distribution, all we need to do is\n",
    "find its mean and variance-covariance matrix.\n",
    "\n",
    "But in fact we’ve already done this, in [(14.6)](#equation-lss-mut-linear-models) and [(14.7)](#equation-eqsigmalaw-linear-models).\n",
    "\n",
    "Letting $ \\mu_t $ and $ \\Sigma_t $ be as defined by these equations,\n",
    "we have\n",
    "\n",
    "\n",
    "<a id='equation-lss-mgs-x'></a>\n",
    "$$\n",
    "x_t \\sim N(\\mu_t, \\Sigma_t) \\tag{11}\n",
    "$$\n",
    "\n",
    "By similar reasoning combined with [(14.8)](#equation-lss-umy) and [(14.9)](#equation-lss-uvy),\n",
    "\n",
    "\n",
    "<a id='equation-lss-mgs-y'></a>\n",
    "$$\n",
    "y_t \\sim N(G \\mu_t, G \\Sigma_t G') \\tag{12}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ensemble Interpretations\n",
    "\n",
    "How should we interpret the distributions defined by [(14.11)](#equation-lss-mgs-x)–[(14.12)](#equation-lss-mgs-y)?\n",
    "\n",
    "Intuitively, the probabilities in a distribution correspond to relative frequencies in a large population drawn from that distribution.\n",
    "\n",
    "Let’s apply this idea to our setting, focusing on the distribution of $ y_T $ for fixed $ T $.\n",
    "\n",
    "We can generate independent draws of $ y_T $ by repeatedly simulating the\n",
    "evolution of the system up to time $ T $, using an independent set of\n",
    "shocks each time.\n",
    "\n",
    "The next figure shows 20 simulations, producing 20 time series for $ \\{y_t\\} $, and hence 20 draws of $ y_T $.\n",
    "\n",
    "The system in question is the univariate autoregressive model [(14.3)](#equation-eq-ar-rep).\n",
    "\n",
    "The values of $ y_T $ are represented by black dots in the left-hand figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def cross_section_plot(A,\n",
    "                   C,\n",
    "                   G,\n",
    "                   T=20,                 # Set the time\n",
    "                   ymin=-0.8,\n",
    "                   ymax=1.25,\n",
    "                   sample_size = 20,     # 20 observations/simulations\n",
    "                   n=4):                 # The number of dimensions for the initial x0\n",
    "\n",
    "    ar = LinearStateSpace(A, C, G, mu_0=np.ones(n))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.grid(alpha=0.4)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_ylabel('$y_t$', fontsize=12)\n",
    "    ax.set_xlabel('time', fontsize=12)\n",
    "    ax.vlines((T,), -1.5, 1.5)\n",
    "\n",
    "    ax.set_xticks((T,))\n",
    "    ax.set_xticklabels(('$T$',))\n",
    "\n",
    "    sample = []\n",
    "    for i in range(sample_size):\n",
    "        rcolor = random.choice(('c', 'g', 'b', 'k'))\n",
    "        x, y = ar.simulate(ts_length=T+15)\n",
    "        y = y.flatten()\n",
    "        ax.plot(y, color=rcolor, lw=1, alpha=0.5)\n",
    "        ax.plot((T,), (y[T],), 'ko', alpha=0.5)\n",
    "        sample.append(y[T])\n",
    "\n",
    "    y = y.flatten()\n",
    "    axes[1].set_ylim(ymin, ymax)\n",
    "    axes[1].set_ylabel('$y_t$', fontsize=12)\n",
    "    axes[1].set_xlabel('relative frequency', fontsize=12)\n",
    "    axes[1].hist(sample, bins=16, density=True, orientation='horizontal', alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ϕ_1, ϕ_2, ϕ_3, ϕ_4 = 0.5, -0.2, 0, 0.5\n",
    "σ = 0.1\n",
    "\n",
    "A_2 = [[ϕ_1, ϕ_2, ϕ_3, ϕ_4],\n",
    "       [1,     0,     0,     0],\n",
    "       [0,     1,     0,     0],\n",
    "       [0,     0,     1,     0]]\n",
    "\n",
    "C_2 = [[σ], [0], [0], [0]]\n",
    "\n",
    "G_2 = [1, 0, 0, 0]\n",
    "\n",
    "cross_section_plot(A_2, C_2, G_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In the right-hand figure, these values are converted into a rotated histogram\n",
    "that shows relative frequencies from our sample of 20 $ y_T $’s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is another figure, this time with 100 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "t = 100\n",
    "cross_section_plot(A_2, C_2, G_2, T=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let’s now try with 500,000 observations, showing only the histogram (without rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "ymin=-0.8\n",
    "ymax=1.25\n",
    "sample_size = 500_000\n",
    "\n",
    "ar = LinearStateSpace(A_2, C_2, G_2, mu_0=np.ones(4))\n",
    "fig, ax = plt.subplots()\n",
    "x, y = ar.simulate(sample_size)\n",
    "mu_x, mu_y, Sigma_x, Sigma_y = ar.stationary_distributions()\n",
    "f_y = norm(loc=float(mu_y), scale=float(np.sqrt(Sigma_y)))\n",
    "y = y.flatten()\n",
    "ygrid = np.linspace(ymin, ymax, 150)\n",
    "\n",
    "ax.hist(y, bins=50, density=True, alpha=0.4)\n",
    "ax.plot(ygrid, f_y.pdf(ygrid), 'k-', lw=2, alpha=0.8, label=r'true density')\n",
    "ax.set_xlim(ymin, ymax)\n",
    "ax.set_xlabel('$y_t$', fontsize=12)\n",
    "ax.set_ylabel('relative frequency', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The black line is the population density of $ y_T $ calculated from [(14.12)](#equation-lss-mgs-y).\n",
    "\n",
    "The histogram and population distribution are close, as expected.\n",
    "\n",
    "By looking at the figures and experimenting with parameters, you will gain a\n",
    "feel for how the population distribution depends on the model primitives [listed above](#lss-pgs), as intermediated by\n",
    "the distribution’s sufficient statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ensemble Means\n",
    "\n",
    "In the preceding figure, we approximated the population distribution of $ y_T $ by\n",
    "\n",
    "1. generating $ I $ sample paths (i.e., time series) where $ I $ is a large number  \n",
    "1. recording each observation $ y^i_T $  \n",
    "1. histogramming this sample  \n",
    "\n",
    "\n",
    "Just as the histogram approximates the population distribution, the *ensemble* or\n",
    "*cross-sectional average*\n",
    "\n",
    "$$\n",
    "\\bar y_T := \\frac{1}{I} \\sum_{i=1}^I y_T^i\n",
    "$$\n",
    "\n",
    "approximates the expectation $ \\mathbb{E} [y_T] = G \\mu_T $ (as implied by the law of large numbers).\n",
    "\n",
    "Here’s a simulation comparing the ensemble averages and population means at time points $ t=0,\\ldots,50 $.\n",
    "\n",
    "The parameters are the same as for the preceding figures,\n",
    "and the sample size is relatively small ($ I=20 $).\n",
    "\n",
    "\n",
    "<a id='lss-em-fig'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "I = 20\n",
    "T = 50\n",
    "ymin = -0.5\n",
    "ymax = 1.15\n",
    "\n",
    "ar = LinearStateSpace(A_2, C_2, G_2, mu_0=np.ones(4))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ensemble_mean = np.zeros(T)\n",
    "for i in range(I):\n",
    "    x, y = ar.simulate(ts_length=T)\n",
    "    y = y.flatten()\n",
    "    ax.plot(y, 'c-', lw=0.8, alpha=0.5)\n",
    "    ensemble_mean = ensemble_mean + y\n",
    "\n",
    "ensemble_mean = ensemble_mean / I\n",
    "ax.plot(ensemble_mean, color='b', lw=2, alpha=0.8, label='$\\\\bar y_t$')\n",
    "m = ar.moment_sequence()\n",
    "\n",
    "population_means = []\n",
    "for t in range(T):\n",
    "    μ_x, μ_y, Σ_x, Σ_y = next(m)\n",
    "    population_means.append(float(μ_y))\n",
    "\n",
    "ax.plot(population_means, color='g', lw=2, alpha=0.8, label='$G\\mu_t$')\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_xlabel('time', fontsize=12)\n",
    "ax.set_ylabel('$y_t$', fontsize=12)\n",
    "ax.legend(ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The ensemble mean for $ x_t $ is\n",
    "\n",
    "$$\n",
    "\\bar x_T := \\frac{1}{I} \\sum_{i=1}^I x_T^i \\to \\mu_T\n",
    "\\qquad (I \\to \\infty)\n",
    "$$\n",
    "\n",
    "The limit $ \\mu_T $ is a  “long-run average”.\n",
    "\n",
    "(By *long-run average* we mean the average for an infinite ($ I = \\infty $)  number of sample $ x_T $’s)\n",
    "\n",
    "Another application of the law of large numbers assures us that\n",
    "\n",
    "$$\n",
    "\\frac{1}{I} \\sum_{i=1}^I (x_T^i - \\bar x_T) (x_T^i - \\bar x_T)' \\to \\Sigma_T\n",
    "\\qquad (I \\to \\infty)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Joint Distributions\n",
    "\n",
    "In the preceding discussion, we looked at the distributions of $ x_t $ and\n",
    "$ y_t $ in isolation.\n",
    "\n",
    "This gives us useful information but doesn’t allow us to answer questions like\n",
    "\n",
    "- what’s the probability that $ x_t \\geq 0 $ for all $ t $?  \n",
    "- what’s the probability that the process $ \\{y_t\\} $ exceeds some value $ a $ before falling below $ b $?  \n",
    "- etc., etc.  \n",
    "\n",
    "\n",
    "Such questions concern the *joint distributions* of these sequences.\n",
    "\n",
    "To compute the joint distribution of $ x_0, x_1, \\ldots, x_T $, recall\n",
    "that joint and conditional densities are linked by the rule\n",
    "\n",
    "$$\n",
    "p(x, y) = p(y \\, | \\, x) p(x)\n",
    "\\qquad \\text{(joint }=\\text{ conditional }\\times\\text{ marginal)}\n",
    "$$\n",
    "\n",
    "From this rule we get $ p(x_0, x_1) = p(x_1 \\,|\\, x_0) p(x_0) $.\n",
    "\n",
    "The Markov property $ p(x_t \\,|\\, x_{t-1}, \\ldots, x_0) =  p(x_t \\,|\\, x_{t-1}) $ and repeated applications of the preceding rule lead us to\n",
    "\n",
    "$$\n",
    "p(x_0, x_1, \\ldots, x_T) =  p(x_0) \\prod_{t=0}^{T-1} p(x_{t+1} \\,|\\, x_t)\n",
    "$$\n",
    "\n",
    "The marginal $ p(x_0) $ is just the primitive $ N(\\mu_0, \\Sigma_0) $.\n",
    "\n",
    "In view of [(14.1)](#equation-st-space-rep), the conditional densities are\n",
    "\n",
    "$$\n",
    "p(x_{t+1} \\,|\\, x_t) = N(Ax_t, C C')\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Noisy Observations\n",
    "\n",
    "In some settings, the observation equation $ y_t = Gx_t $ is modified to\n",
    "include an error term.\n",
    "\n",
    "Often this error term represents the idea that the true state can only be\n",
    "observed imperfectly.\n",
    "\n",
    "To include an error term in the observation we introduce\n",
    "\n",
    "- An IID sequence of $ \\ell \\times 1 $ random vectors $ v_t \\sim N(0,I) $.  \n",
    "- A $ k \\times \\ell $ matrix $ H $.  \n",
    "\n",
    "\n",
    "and extend the linear state-space system to\n",
    "\n",
    "\n",
    "<a id='equation-st-space-rep-noisy'></a>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    x_{t+1} & =  A x_t + C w_{t+1}   \\\\\n",
    "    y_t &  =  G x_t + H v_t \\nonumber \\\\\n",
    "    x_0 & \\sim N(\\mu_0, \\Sigma_0) \\nonumber\n",
    "\\end{aligned} \\tag{17}\n",
    "$$\n",
    "\n",
    "The sequence $ \\{v_t\\} $ is assumed to be independent of $ \\{w_t\\} $.\n",
    "\n",
    "The process $ \\{x_t\\} $ is not modified by noise in the observation\n",
    "equation and its moments, distributions and stability properties remain the same.\n",
    "\n",
    "The unconditional moments of $ y_t $ from [(14.8)](#equation-lss-umy) and [(14.9)](#equation-lss-uvy)\n",
    "now become\n",
    "\n",
    "\n",
    "<a id='equation-lss-umy-2'></a>\n",
    "$$\n",
    "\\mathbb{E} [y_t] = \\mathbb{E} [G x_t + H v_t] = G \\mu_t \\tag{18}\n",
    "$$\n",
    "\n",
    "The variance-covariance matrix of $ y_t $ is easily shown to be\n",
    "\n",
    "\n",
    "<a id='equation-lss-uvy-2'></a>\n",
    "$$\n",
    "\\textrm{Var} [y_t] = \\textrm{Var} [G x_t + H v_t] = G \\Sigma_t G' + HH' \\tag{19}\n",
    "$$\n",
    "\n",
    "The distribution of $ y_t $ is therefore\n",
    "\n",
    "$$\n",
    "y_t \\sim N(G \\mu_t, G \\Sigma_t G' + HH')\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1619590833.6021376,
  "filename": "linear_models.md",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "title": "Linear State Space Models"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
