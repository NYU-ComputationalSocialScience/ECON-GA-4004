{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3504fa0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4543ae1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import quantecon as qe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b3412",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a hidden Markov model?\n",
    "\n",
    "A hidden Markov model is a model in which there is a hidden state, $x_t$, that follows a Markov process and an observed state, $y_t$, that is a function of $x_t$ and randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e40c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Examples of hidden Markov models (and hidden states)\n",
    "\n",
    "It isn't always obvious to think about what hidden states (i.e., variables that one can't observe) are and how they would be useful.\n",
    "\n",
    "Let's begin by presenting a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f52b22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example 1: Cell phone location**\n",
    "\n",
    "In spite of what it may appear, your phone cannot directly measure your physical location.\n",
    "\n",
    "The phone listens for radio signals from various satellites and uses the relative strengths (and time to receive the signal) to uncover where you are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385a6ac7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example 2: Stock market**\n",
    "\n",
    "Some people assert that the stock market follows \"animal spirits\" with bear runs being periods of time in which the value of stocks (typically) declines and bull runs being periods of time in which the value of stocks (typically) rise.\n",
    "\n",
    "The current animal spirit is not necessarily observable, but we can observe stock returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce6d76",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example 3: Animal behavior**\n",
    "\n",
    "It can be difficult to directly observe what ocean creatures are doing at various moments in time.\n",
    "\n",
    "In order to learn more about what these animals do, researchers often tag these animals with GPS trackers. They can then learn more about the different types of behavior animals might be exhibiting. For example:\n",
    "\n",
    "* When the animal slows/stops its movement that it is likely to be sleeping\n",
    "* Short bursts of rapid movement may indicate hunting (or fleeing a predator!)\n",
    "\n",
    "I'm admittedly no ecologist so I refer any questions of how this works to [researchers in this field](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5383489/) and this [excellent podcast](https://www.learnbayesstats.com/episode/14-hidden-markov-models-statistical-ecology-with-vianey-leos-barajas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bf6d4b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example 4: Speech recognition**\n",
    "\n",
    "Imagine that you were tasked with identifying whether a certain sports announcer lead to people changing the channel. Hypothetically you could determine who was speaking at each moment of the broadcast, but collecting sufficient data to make a reliable inference would be difficult.\n",
    "\n",
    "One alternative you could use is to make the speaker a hidden state and use audio data as the observed data to determine who was speaking at each moment in time.\n",
    "\n",
    "(We have spoken with data scientists at large media companies who have been tasked with work that is very close to this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369835a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HMM examples (with math!)\n",
    "\n",
    "We next begin working with some simplified examples of hidden Markov models.\n",
    "\n",
    "We will do a simple discrete state example and a simple continuous state example. In both cases, we will begin with a somewhat static model and then make it dynamic.\n",
    "\n",
    "The theme in these examples is to \"walk before you run\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f416816",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Discrete example\n",
    "\n",
    "We begin with a version of the \"canonical\" HMM.\n",
    "\n",
    "Imagine that we are a pyschologist and are trying to learn about whether an individual in our care is happy or unhappy. Every day the individual chooses whether to play one of two card games: \n",
    "\n",
    "* Solitaire ($S$) or\n",
    "* go fish ($G$)\n",
    "\n",
    "We know when the individual is happy ($H$) that they play go fish with probability 0.80 and solitaire with probability 0.20. When the individual is unhappy ($U$), they play go fish with probability 0.40 and solitaire with probability 0.60.\n",
    "\n",
    "Additionally, historically we have found that the individual is happy 60\\% of the time and unhappy 40\\% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfc517",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Imagine that we see an individual choose to play go fish today. What is the probability that they are happy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f6bcd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can learn abaout this using conditional probabilities (aka Bayes law)!\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(H | G) &= \\frac{\\text{Prob}(H) \\text{Prob}(G | H)}{\\text{Prob}(G)} \\\\\n",
    "  &= \\frac{\\text{Prob}(H) \\text{Prob}(G | H)}{\\text{Prob}(G | H) \\text{Prob}(H) + \\text{Prob}(G | S) \\text{Prob}(S)} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78477131",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_H1, p_U1 = 0.6, 0.4\n",
    "p_GgH, p_SgH = 0.8, 0.2\n",
    "p_GgU, p_SgU = 0.4, 0.6\n",
    "\n",
    "(p_H1 * p_GgH) / (p_GgH*p_H1 + p_GgU*p_U1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b76d68",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Discrete example with dynamics\n",
    "\n",
    "Now imagine that we're able to observe two days of whether the individual plays solitaire or go fish.\n",
    "\n",
    "Let the games that the individual plays on each day be\n",
    "\n",
    "* Day 1: Go fish\n",
    "* Day 2: Solitaire\n",
    "\n",
    "What is the probability that the individual is happy on each day?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29750b0c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One way to proceed is to simply calculate the day by day probabilities separately using the same rules as above.\n",
    "\n",
    "What if instead, we account of the fact that if someone is happy yesterday, then they are likely to be happy today?\n",
    "\n",
    "More specifically, we will assume a that an individual's mood follows a particular Markov chain where the states are $\\{H, U\\}$ and the transition matrix is\n",
    "\n",
    "$$\\begin{bmatrix} 0.95 & 0.05 \\\\ 0.2 & 0.8 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1947ceb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_HH, p_HU, p_UH, p_UU = 0.95, 0.05, 0.2, 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c74e5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's write down our conditional probabilities:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(H_1 | \\{G_1, S_2\\}) &= \\frac{\\text{Prob}(H_1) \\text{Prob}(G_1, S_2 | H_1)}{\\text{Prob}(G_1, S_2)} \\\\\n",
    "  \\text{Prob}(H_2 | \\{G_1, S_2\\}) &= \\frac{\\text{Prob}(H_2) \\text{Prob}(G_1, S_2 | H_2)}{\\text{Prob}(G_1, S_2)} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753596a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Beginning with the components of the first equation,\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(G_1, S_2) &= \\text{Prob}(G_1, S_2 | H_1 H_2) \\text{Prob}(H_1 H_2) \\\\\n",
    "  &\\quad + \\text{Prob}(G_1, S_2 | H_1 U_2) \\text{Prob}(H_1 U_2) \\\\\n",
    "  &\\quad + \\text{Prob}(G_1, S_2 | U_1 H_2) \\text{Prob}(U_1 H_2) \\\\\n",
    "  &\\quad + \\text{Prob}(G_1, S_2 | U_1 U_2) \\text{Prob}(U_1 U_2) \\\\\n",
    "  &= \\text{Prob}(G_1 | H_1) \\text{Prob}(S_2 | H_2) \\text{Prob}(H_2 | H_1) \\text{Prob}(H_1) \\\\\n",
    "  &\\quad+ \\text{Prob}(G_1 | H_1) \\text{Prob}(S_2 | U_2) \\text{Prob}(U_2 | H_1) \\text{Prob}(H_1) \\\\\n",
    "  &\\quad+ \\text{Prob}(G_1 | U_1) \\text{Prob}(S_2 | H_2) \\text{Prob}(H_2 | U_1) \\text{Prob}(U_1) \\\\\n",
    "  &\\quad+ \\text{Prob}(G_1 | U_1) \\text{Prob}(S_2 | U_2) \\text{Prob}(U_2 | U_1) \\text{Prob}(U_1) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(G_1, S_2 | H_1) &= P(G_1 | H_1) P(S_2 | H_1) \\\\\n",
    "  &= P(G_1 | H_1) (P(S_2 | H_2) P(H_2 | H_1) + P(S_2 | U_2) P(U_2 | H_1))\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec71b3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Prob(H1 | G1, S2)\n",
    "p_G1S2 = (\n",
    "    (p_GgH*p_SgH*p_HH*p_H1) +\n",
    "    (p_GgH*p_SgU*p_HU*p_H1) +\n",
    "    (p_GgU*p_SgH*p_UH*p_U1) +\n",
    "    (p_GgU*p_SgU*p_UU*p_U1)\n",
    ")\n",
    "p_G1S2gH1 = p_GgH*(p_SgH*p_HH + p_SgU*p_HU)\n",
    "\n",
    "p_H1gG1S2 = (p_H1 * p_G1S2gH1) / p_G1S2\n",
    "p_H1gG1S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c28701",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now onto the components of the second equation,\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(H_2) &= \\text{Prob}(H_2 | H_1) \\text{Prob}(H_1) + \\text{Prob}(H_2 | U_1) \\text{Prob}(U_1)\n",
    "\\end{align*}\n",
    "\n",
    "and\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(H_1 | H_2) &= \\frac{\\text{Prob}(H_1) \\text{Prob}(H_2 | H_1)}{\\text{Prob}(H_2)} \\\\\n",
    "  \\text{Prob}(U_1 | H_2) &= \\frac{\\text{Prob}(U_1) \\text{Prob}(H_2 | U_1)}{\\text{Prob}(H_2)}\n",
    "\\end{align*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align*}\n",
    "  \\text{Prob}(G_1 S_2 | H_2) &= \\text{Prob}(G_1 S_2 | H_1 H_2) \\text{Prob}(H_1 | H_2) \\\\\n",
    "  &\\quad + \\text{Prob}(G_1 S_2 | U_1 H_2) \\text{Prob}(U_1 | H_2) \\\\\n",
    "  &= \\text{Prob}(G_1 | H_1) \\text{Prob}(S_2 | H_2) \\text{Prob}(H_1 | H_2) \\\\\n",
    "  &\\quad + \\text{Prob}(G_1 | U_1) \\text{Prob}(S_2 | H_2)  \\text{Prob}(U_1 | H_2) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7908a20",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_H2 = (p_HH*p_H1 + p_UH*p_U1)\n",
    "\n",
    "p_H1gH2 = (p_H1*p_HH)/p_H2\n",
    "p_U1gH2 = (p_U1*p_UH)/p_H2\n",
    "\n",
    "p_G1S2gH2 = p_GgH*p_SgH*p_H1gH2 + p_GgU*p_SgH*p_U1gH2\n",
    "\n",
    "p_H2gG1S2 = (p_H2 * p_G1S2gH2) / p_G1S2\n",
    "p_H2gG1S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81764717",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice how with two observations we start to learn a little more about which states generated the observations... The observation from period 2 told us that it was less likely that the individual actually was happy yesterday!\n",
    "\n",
    "Conditional probabilities are going to be at the center of EVERY HMM!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe6768",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Continuous example\n",
    "\n",
    "Let $x_0$ be an $n \\times 1$ random vector and $y_0$ be a $p \\times 1$ random vector such that\n",
    "\n",
    "\\begin{align*}\n",
    "  x_0 &\\sim N(\\bar{x}_0, \\Sigma_0) \\\\\n",
    "  y_0 &= G x_0 + v_0 \\\\\n",
    "  v_0 &\\sim N(0, R)\n",
    "\\end{align*}\n",
    "\n",
    "where $v_0$ is orthogonal to $x_0$, $R$ is a $p \\times p$ positive definite matrix, and $\\Sigma$ is an $n \\times n$ positive definite matrix.\n",
    "\n",
    "We will consider the problem of someone who observes $y_0$ but not $x_0$. Additionally, the individual knows $\\bar{x}_0$, $\\Sigma_0$, $G$, and $R$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d74e61",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**What do we know?**\n",
    "\n",
    "We know that\n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix} x_0 \\\\ y_0 \\end{bmatrix} \\sim N \\left(\\mu, \\Sigma \\right)\n",
    "\\end{align*}\n",
    "\n",
    "where\n",
    "\n",
    "$$\\mu = \\begin{bmatrix} \\bar{x} \\\\ G \\bar{x} \\end{bmatrix},\\; \\Sigma = \\begin{bmatrix} \\Sigma_0 & \\Sigma_0 G' \\\\ G \\Sigma_0 & G \\Sigma_0 G' + R \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af7fd1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Conditional normal equations**\n",
    "\n",
    "Conditional on knowing $y_0$, what is the distribution of $x_0$?\n",
    "\n",
    "$$x_0 | y_0 \\sim N(\\tilde{\\mu}, \\tilde{\\Sigma})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\tilde{\\mu} = \\bar{x_0} + \\Sigma_0 G'(G \\Sigma_0 G' + R)^{-1} (y_0 - G \\bar{x_0})$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\tilde{\\Sigma} = \\Sigma_0 - \\Sigma_0 G' (G \\Sigma_0 G' + R)^{-1} G \\Sigma_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14884d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**What do we learn from these equations?**\n",
    "\n",
    "* $R = \\mathbb{0} \\rightarrow$\n",
    "  - $G \\tilde{\\mu} = y_0$\n",
    "  - $\\tilde{\\Sigma} = 0$\n",
    "* $\\tilde{\\mu}$ effectively is scaling the difference between observed $y_0$ and expected $G \\bar{x}_0$.\n",
    "  - $y_0 - G \\bar{x}_0 > 0$ implies either $\\tilde{\\mu} > \\bar{x}_0$ or $\\tilde{\\mu} < \\bar{x}_0$ based on the value of $\\Sigma_0 G'(G \\Sigma G' + R)^{-1}$\n",
    "  - $y_0 - G \\bar{x}_0 < 0$ implies the opposite of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5f19a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Continuous with \"dynamics\"\n",
    "\n",
    "Suppose that we have a two observation time series:\n",
    "\n",
    "$$\\{x_0, y_0, x_1, y_1\\}$$\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{align*}\n",
    "  x_0 &\\sim N(\\bar{x}_0, \\Sigma_0) \\\\\n",
    "  y_0 &= G x_0 + v_0 \\\\\n",
    "  v_0 &\\sim N(0, R) \\\\\n",
    "  x_1 &= A x_0 + C w_1 \\\\\n",
    "  y_1 &= G x_1 + v_1\n",
    "\\end{align*}\n",
    "\n",
    "We will explore the probability distribution over $x_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cddcc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using what we computed in the previous section, we can determine that\n",
    "\n",
    "\\begin{align*}\n",
    "  x_1 | y_0 \\sim N(A \\tilde{\\mu}_0, A \\tilde{\\Sigma}_0 A' + C C')\n",
    "\\end{align*}\n",
    "\n",
    "Let\n",
    "\n",
    "\\begin{align*}\n",
    "  \\hat{\\mu}_1 &= A \\tilde{\\mu}_0 \\\\\n",
    "  \\hat{\\Sigma}_1 &= A \\tilde{\\Sigma}_0 A' + C C'\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7cb54",
   "metadata": {},
   "source": [
    "Starting from here, we have a very similar problem to what we solved in the static component!\n",
    "\n",
    "We want to compute the distribution of $x_1 | y_1$. We can do this using the same formulas as in part 1 to get\n",
    "\n",
    "$$x_1 | y_1 \\sim N(\\tilde{\\mu}_1, \\tilde{\\Sigma}_1)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\tilde{\\mu}_1 = \\hat{\\mu}_1 + \\hat{\\Sigma}_1 G'(G \\hat{\\Sigma}_1 G' + R)^{-1} (y_1 - G \\hat{\\mu}_1)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\tilde{\\Sigma}_1 = \\hat{\\Sigma}_1 - \\hat{\\Sigma}_1 G' (G \\hat{\\Sigma}_1 G' + R)^{-1} G \\hat{\\Sigma}_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119de971",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This dynamic example in a continuous state/observation equation is a preface to linear state space models and the Kalman filter.\n",
    "\n",
    "We will explore these topics in more depth soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db15cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete state HMMs\n",
    "\n",
    "Now that we've done some two-period examples, we're going to move on to a $T$ period examples.\n",
    "\n",
    "Consider the following setting:\n",
    "\n",
    "The weekly returns for a particular stock alternate between bear and bull cycles according to a Markov chain. You have been told that the transition matrix that describes this Markov chain is given by:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix} p_{\\text{bear}} & 1 - p_{\\text{bear}} \\\\ 1 - p_{\\text{bull}} & p_{\\text{bull}} \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "where $p_{\\text{bear}} = 0.85$ and $p_{\\text{bull}} = 0.7$.\n",
    "\n",
    "Returns can either be negative ($N$), zero ($Z$), or positive ($P$).\n",
    "\n",
    "The weekly returns that an individual earns are random and depend on whether the market is in a bear or bull cycle.\n",
    "\n",
    "\\begin{align*}\n",
    "  r_{\\text{bear}} = \\begin{cases} N \\text{ with probability } 0.2 \\\\ Z \\text{ with probability } 0.75 \\\\ P \\text{ with probability } 0.05 \\end{cases} \\\\\n",
    "  r_{\\text{bull}} = \\begin{cases} N \\text{ with probability } 0.1 \\\\ Z \\text{ with probability } 0.6 \\\\ P \\text{ with probability } 0.3 \\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7c33d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Simulate data**\n",
    "\n",
    "We start by simulating the output of such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113121fc",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Two years of data\n",
    "T = 104\n",
    "\n",
    "p_bear = 0.85\n",
    "p_bull = 0.7\n",
    "P = np.array([[p_bear, 1 - p_bear], [1 - p_bull, p_bull]])\n",
    "\n",
    "r_bear_probs = np.array([0.2, 0.75, 0.05])\n",
    "r_bull_probs = np.array([0.1, 0.6, 0.3])\n",
    "\n",
    "mc = qe.MarkovChain(P)\n",
    "\n",
    "\n",
    "def simulate_bb_model(mc, r_bear_probs, r_bull_probs, T):\n",
    "    # First simulate the bear/bull component\n",
    "    bb_idx = mc.simulate_indices(T)\n",
    "\n",
    "    realized_returns = np.zeros(T, dtype=int)\n",
    "    for t, bb in enumerate(bb_idx):\n",
    "        # Build the discrete random variable for each period\n",
    "        if bb == 0:\n",
    "            r_probs = qe.DiscreteRV(r_bear_probs)\n",
    "        else:\n",
    "            r_probs = qe.DiscreteRV(r_bull_probs)\n",
    "\n",
    "        realized_returns[t] = r_probs.draw()[0]\n",
    "\n",
    "    return bb_idx, realized_returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2105da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examining the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bd3c0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bb_idx, realized_returns = simulate_bb_model(mc, r_bear_probs, r_bull_probs, 104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7edb1d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bb_model_output(bb_idx, realized_returns):\n",
    "    # Relevant plotting stuff\n",
    "    T = bb_idx.shape[0]\n",
    "    tvalues = np.arange(T)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "    ax0, ax1 = ax\n",
    "\n",
    "    ax0.scatter(tvalues, bb_idx)\n",
    "    ax0.set_yticks([0, 1])\n",
    "    ax0.set_yticklabels([\"Bear\", \"Bull\"])\n",
    "    ax0.spines[\"right\"].set_visible(False)\n",
    "    ax0.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    ax1.scatter(tvalues, realized_returns)\n",
    "    ax1.set_yticks([0, 1, 2])\n",
    "    ax1.set_yticklabels([\"Negative\", \"Zero\", \"Positive\"])\n",
    "    ax1.spines[\"right\"].set_visible(False)\n",
    "    ax1.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    pass\n",
    "\n",
    "plot_bb_model_output(bb_idx, realized_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b9663",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Objects (mostly probabilities) that we might be interested in:\n",
    "\n",
    "1. $P(x_t | y^t)$: Can we use the history of observed returns to identify whether we are currently in a bear or bull market -- This is known as the \"filtering problem\".\n",
    "2. $P(x_\\tau | y^t)$ where $\\tau < t$: Can we use the history of observed returns to identify whether we were in a bear or bull market in the past -- This is known as the \"smoothing problem\"\n",
    "3. $P(x_\\tau | y^t)$ where $\\tau > t$: Can we use the data we've observed until now to predict the state in the future -- This is known as the \"forecasting (or prediction) problem\"\n",
    "4. $P(y^t)$: What is the likelihood of having observed the returns that we see -- This is known as the \"likelihood problem\"\n",
    "5. $\\hat{x}^t$: What is the most likely sequence of market conditions to have generated the data we see -- This is known as the \"most likely hidden path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1c5ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Filtering problem\n",
    "\n",
    "The filtering problem is about using the history of observed data to identify the current hidden state, i.e. $P(x_t | y^t)$\n",
    "\n",
    "The probabilities will be computed recursively.\n",
    "\n",
    "Let\n",
    "\n",
    "$$\\alpha(x_t) \\equiv P(x_t, y^{t})$$\n",
    "\n",
    "then, $\\alpha(x_0) = P(y_0 | x_0) P(x_0)$\n",
    "\n",
    "Recursively, if we have $\\alpha(x_{t-1})$ then\n",
    "\n",
    "\\begin{align*}\n",
    "  \\alpha(x_t) &= P(x_t, y^{t}) \\\\\n",
    "  &= \\sum_{x_{t-1}} P(x_t, x_{t-1} y^{t}) \\\\\n",
    "  &= \\sum_{x_{t-1}} P(y_t | x_{t-1}, x_{t}) P(y^{t-1} | x_{t-1}, x_{t}) P(x_{t} x_{t-1}) \\\\\n",
    "  &= P(y_t | x_{t}) \\sum_{x_{t-1}} P(y^{t-1} | x_{t-1}) P(x_{t} | x_{t-1}) P(x_{t-1}) \\\\\n",
    "  &= P(y_t | x_{t}) \\sum_{x_{t-1}} P(y^{t-1}, x_{t-1}) P(x_{t} | x_{t-1}) \\\\\n",
    "  &= P(y_t | x_{t}) \\sum_{x_{t-1}} \\alpha(x_{t-1}) P(x_{t} | x_{t-1}) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now notice that\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x_t | y^t) &= \\frac{P(x_t, y^t)}{P(y^t)} \\\\\n",
    "  &\\propto P(x_t, y^t) \\\\\n",
    "  &= \\alpha(x_t)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8fe82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's see whether we can figure out what is the probability of being in a bear/bull market in period 52:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c3cda2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Allocate memory for our alphas\n",
    "t_of_interest = 104\n",
    "alphas = np.zeros((t_of_interest, 2))\n",
    "\n",
    "# Solve for period 0 -- Equal probability of starting\n",
    "# in bear/bull market\n",
    "alphas[0, 0] = r_bear_probs[realized_returns[0]] * 0.5\n",
    "alphas[0, 1] = r_bull_probs[realized_returns[0]] * 0.5\n",
    "\n",
    "for t in range(1, t_of_interest):\n",
    "\n",
    "    # Sum over  x_{t-1}\n",
    "    predictor_bear = 0.0\n",
    "    predictor_bull = 0.0\n",
    "    for j in range(2):\n",
    "        #            alpha(x_{t-1}) P(x_t | x_{t-1})\n",
    "        predictor_bear += alphas[t-1, j]*mc.P[j, 0]\n",
    "        predictor_bull += alphas[t-1, j]*mc.P[j, 1]\n",
    "\n",
    "    alphas[t, 0] = r_bear_probs[realized_returns[t]]*predictor_bear\n",
    "    alphas[t, 1] = r_bull_probs[realized_returns[t]]*predictor_bull\n",
    "\n",
    "# Convert with normalizing factor!\n",
    "filtering_probs = np.divide(alphas, alphas.sum(axis=1)[:, None])\n",
    "\n",
    "print(f\"Probability of bear/bull is {filtering_probs[-1, :]}\")\n",
    "print(f\"Actual state is {bb_idx[t_of_interest-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fff505",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvalues = np.arange(bb_idx.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "ax[0].scatter(tvalues, bb_idx)\n",
    "ax[1].scatter(tvalues, realized_returns)\n",
    "ax[2].plot(tvalues, filtering_probs[:, 1])\n",
    "ax[2].set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7fb83",
   "metadata": {},
   "source": [
    "**Useful References**\n",
    "\n",
    "* [Blog post by Jonathan Hui](https://jonathan-hui.medium.com/machine-learning-hidden-markov-model-hmm-31660d217a61)\n",
    "* [Slides by Martin Haugh @ Columbia](http://www.columbia.edu/~mh2078/MachineLearningORFE/HMMs_MasterSlides.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
