{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d85636c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hidden Markov Models (continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb71704",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import quantecon as qe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9c9b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44efec1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What is a hidden Markov model?**\n",
    "\n",
    "A hidden Markov model is a model in which there is a hidden state, $x_t$, that follows a Markov process and an observed state, $y_t$, that is a function of $x_t$ and randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbafe9c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Conditional probabilities everywhere!**\n",
    "\n",
    "Conditional probabilities are crucial to being able to evaluate objects of interest in the HMMs because there is the unobserved dependence.\n",
    "\n",
    "We repeatedly use several laws of probability to manipulate the probabilites into something we can compute:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26e54b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Bayes law_\n",
    "\n",
    "Bayes law states,\n",
    "\n",
    "$$P(A | B) = \\frac{P(A) P(B | A)}{P(B)}$$\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1638fd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Definition of a conditional probability_\n",
    "\n",
    "The definition of conditional probability states:\n",
    "\n",
    "$$P(A | B) = \\frac{P(A, B)}{P(B)}$$\n",
    "\n",
    "which implies\n",
    "\n",
    "$$P(A, B) = P(A | B) P(B)$$\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Conditional_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a65cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Law of total probability_\n",
    "\n",
    "Let $A$ be an event in sample space $X$ and let $\\{B_n\\}$ be a finite partition of the sample space. Then,\n",
    "\n",
    "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Law_of_total_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c46426",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Objects of interest**\n",
    "\n",
    "1. ~~$P(x_t | y^t)$: Can we use the history of observed returns to identify whether we are currently in a bear or bull market -- This is known as the \"filtering problem\".~~\n",
    "2. $P(x_\\tau | y^t)$ where $\\tau < t$: Can we use the history of observed returns to identify whether we were in a bear or bull market in the past -- This is known as the \"smoothing problem\"\n",
    "3. $P(x_\\tau | y^t)$ where $\\tau > t$: Can we use the data we've observed until now to predict the state in the future -- This is known as the \"forecasting (or prediction) problem\"\n",
    "4. $P(y^t)$: What is the likelihood of having observed the returns that we see -- This is known as the \"likelihood problem\"\n",
    "5. $\\hat{x}^t$: What is the most likely sequence of market conditions to have generated the data we see -- This is known as the \"most likely hidden path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ed086",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete state HMMs\n",
    "\n",
    "Recall the model we used last time.\n",
    "\n",
    "The weekly returns for a particular stock alternate between bear and bull cycles according to a Markov chain. You have been told that the transition matrix that describes this Markov chain is given by:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix} p_{\\text{bear}} & 1 - p_{\\text{bear}} \\\\ 1 - p_{\\text{bull}} & p_{\\text{bull}} \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "where $p_{\\text{bear}} = 0.85$ and $p_{\\text{bull}} = 0.7$.\n",
    "\n",
    "Returns can either be negative ($N$), zero ($Z$), or positive ($P$).\n",
    "\n",
    "The weekly returns that an individual earns are random and depend on whether the market is in a bear or bull cycle.\n",
    "\n",
    "\\begin{align*}\n",
    "  r_{\\text{bear}} = \\begin{cases} N \\text{ with probability } 0.2 \\\\ Z \\text{ with probability } 0.75 \\\\ P \\text{ with probability } 0.05 \\end{cases} \\\\\n",
    "  r_{\\text{bull}} = \\begin{cases} N \\text{ with probability } 0.1 \\\\ Z \\text{ with probability } 0.6 \\\\ P \\text{ with probability } 0.3 \\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1a023",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Simulate data**\n",
    "\n",
    "We start by simulating the output of such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d16bf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Two years of data\n",
    "T = 104\n",
    "\n",
    "p_bear = 0.85\n",
    "p_bull = 0.7\n",
    "P = np.array([[p_bear, 1 - p_bear], [1 - p_bull, p_bull]])\n",
    "\n",
    "r_bear_probs = np.array([0.2, 0.75, 0.05])\n",
    "r_bull_probs = np.array([0.1, 0.6, 0.3])\n",
    "\n",
    "mc = qe.MarkovChain(P)\n",
    "\n",
    "\n",
    "def simulate_bb_model(mc, r_bear_probs, r_bull_probs, T):\n",
    "    # First simulate the bear/bull component\n",
    "    bb_idx = mc.simulate_indices(T)\n",
    "\n",
    "    realized_returns = np.zeros(T, dtype=int)\n",
    "    for t, bb in enumerate(bb_idx):\n",
    "        # Build the discrete random variable for each period\n",
    "        if bb == 0:\n",
    "            r_probs = qe.DiscreteRV(r_bear_probs)\n",
    "        else:\n",
    "            r_probs = qe.DiscreteRV(r_bull_probs)\n",
    "\n",
    "        realized_returns[t] = r_probs.draw()[0]\n",
    "\n",
    "    return bb_idx, realized_returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750318b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Examining the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7918f6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bb_idx, realized_returns = simulate_bb_model(mc, r_bear_probs, r_bull_probs, 104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eaf14c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bb_model_output(bb_idx, realized_returns):\n",
    "    # Relevant plotting stuff\n",
    "    T = bb_idx.shape[0]\n",
    "    tvalues = np.arange(T)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8, 10), sharex=True)\n",
    "    ax0, ax1 = ax\n",
    "\n",
    "    ax0.scatter(tvalues, bb_idx)\n",
    "    ax0.set_yticks([0, 1])\n",
    "    ax0.set_yticklabels([\"Bear\", \"Bull\"])\n",
    "    ax0.spines[\"right\"].set_visible(False)\n",
    "    ax0.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    ax1.scatter(tvalues, realized_returns)\n",
    "    ax1.set_yticks([0, 1, 2])\n",
    "    ax1.set_yticklabels([\"Negative\", \"Zero\", \"Positive\"])\n",
    "    ax1.spines[\"right\"].set_visible(False)\n",
    "    ax1.spines[\"top\"].set_visible(False)\n",
    "\n",
    "    pass\n",
    "\n",
    "plot_bb_model_output(bb_idx, realized_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3639026",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Filtering problem\n",
    "\n",
    "The filtering problem is about using the history of observed data to identify the current hidden state, i.e. $P(x_t | y^t)$\n",
    "\n",
    "The probabilities will be computed recursively.\n",
    "\n",
    "Let\n",
    "\n",
    "$$\\alpha(x_t) \\equiv P(x_t, y^{t})$$\n",
    "\n",
    "then, $\\alpha(x_0) = P(y_0 | x_0) P(x_0)$\n",
    "\n",
    "Recursively, if we have $\\alpha(x_{t-1})$ then\n",
    "\n",
    "\\begin{align*}\n",
    "  \\alpha(x_t) &= P(x_t, y^{t}) \\\\\n",
    "  &= \\sum_{x_{t-1}} P(x_t, x_{t-1} y^{t}) \\\\\n",
    "  &= \\sum_{x_{t-1}} P(y_t | x_{t-1}, x_{t}) P(y^{t-1} | x_{t-1}, x_{t}) P(x_{t} x_{t-1}) \\\\\n",
    "  &= P(y_t | x_{t}) \\sum_{x_{t-1}} P(y^{t-1} | x_{t-1}) P(x_{t} | x_{t-1}) P(x_{t-1}) \\\\\n",
    "  &= P(y_t | x_{t}) \\sum_{x_{t-1}} P(y^{t-1}, x_{t-1}) P(x_{t} | x_{t-1}) \\\\\n",
    "  &= P(y_t | x_{t}) \\sum_{x_{t-1}} \\alpha(x_{t-1}) P(x_{t} | x_{t-1}) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now notice that\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x_t | y^t) &= \\frac{P(x_t, y^t)}{P(y^t)} \\\\\n",
    "  &\\propto P(x_t, y^t) \\\\\n",
    "  &= \\alpha(x_t)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ce7cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's see whether we can compute the probability of being in a bear/bull market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cba27",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Allocate memory for our alphas\n",
    "t_of_interest = 104\n",
    "alphas = np.zeros((t_of_interest, 2))\n",
    "\n",
    "# Solve for period 0 -- Equal probability of starting\n",
    "# in bear/bull market\n",
    "alphas[0, 0] = r_bear_probs[realized_returns[0]] * 0.5\n",
    "alphas[0, 1] = r_bull_probs[realized_returns[0]] * 0.5\n",
    "\n",
    "for t in range(1, t_of_interest):\n",
    "\n",
    "    # Sum over  x_{t-1}\n",
    "    predictor_bear = 0.0\n",
    "    predictor_bull = 0.0\n",
    "    for j in range(2):\n",
    "        #            alpha(x_{t-1}) P(x_t | x_{t-1})\n",
    "        predictor_bear += alphas[t-1, j]*mc.P[j, 0]\n",
    "        predictor_bull += alphas[t-1, j]*mc.P[j, 1]\n",
    "\n",
    "    alphas[t, 0] = r_bear_probs[realized_returns[t]]*predictor_bear\n",
    "    alphas[t, 1] = r_bull_probs[realized_returns[t]]*predictor_bull\n",
    "\n",
    "# Convert with normalizing factor!\n",
    "filtering_probs = np.divide(alphas, alphas.sum(axis=1)[:, None])\n",
    "\n",
    "print(f\"Probability of bear/bull is {filtering_probs[-1, :]}\")\n",
    "print(f\"Actual state is {bb_idx[t_of_interest-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvalues = np.arange(bb_idx.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "ax[0].scatter(tvalues, bb_idx)\n",
    "ax[1].scatter(tvalues, realized_returns)\n",
    "ax[2].plot(tvalues, filtering_probs[:, 1])\n",
    "ax[2].set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc561e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Smoothing problem\n",
    "\n",
    "The smoothing problem is about using all of the information at hand to determine the likelihood of being in a bear/bull market using all available data.\n",
    "\n",
    "We again define a useful recursion\n",
    "\n",
    "Let\n",
    "\n",
    "$$\\beta(x_t) \\equiv P(y^{t+1:T} | x_t)$$\n",
    "\n",
    "with $\\beta(x_T) = 1$\n",
    "\n",
    "Then,\n",
    "\n",
    "\\begin{align*}\n",
    "  \\beta(x_t) &= P(y^{t+1:T} | x_t) \\\\\n",
    "  &= \\sum_{x_{t+1}} P(y_{t+1}, y^{t+2:T}, x_{t+1} | x_{t}) \\\\\n",
    "  &= \\sum_{x_{t+1}} P(y_{t+1} | y^{t+2:T}, x_{t+1}, x_{t}) P(y^{t+2:T}, x_{t+1} | x_t) \\\\\n",
    "  &= \\sum_{x_{t+1}} P(y_{t+1} | x_{t+1}) P(y^{t+2:T} | x_{t+1}, x_{t}) P(x_{t+1} | x+t) \\\\\n",
    "  &= \\sum_{x_{t+1}} P(y_{t+1} | x_{t+1}) \\beta(x_{t+1}) P(x_{t+1} | x+t) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now notice that\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x_t, y^T) &= P(x_t, y^t, y^{t+1:T}) \\\\\n",
    "  &= P(y^{t+1:T} | x_t, y^t) P(x_t, y^t) \\\\\n",
    "  &= \\beta(x_t) \\alpha(x_t)\n",
    "\\end{align*}\n",
    "\n",
    "and thus,\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x_t | y^T) &= \\frac{\\beta(x_t) \\alpha(x_t)}{\\sum_{x} \\beta(x_t=x) \\alpha(x_t=x)} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f166369",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Allocate memory for our alphas\n",
    "betas = np.zeros((t_of_interest, 2))\n",
    "\n",
    "# Solve for period T -- This is just defined as 1\n",
    "betas[-1, 0] = 1\n",
    "betas[-1, 1] = 1\n",
    "\n",
    "for tp1 in range(t_of_interest-1, 0, -1):\n",
    "\n",
    "    # Sum over  x_{t-1} (exponent of sum is product of exponents)\n",
    "    value_bear = 0.0\n",
    "    value_bull = 0.0\n",
    "    for j in range(2):\n",
    "        _probs = r_bear_probs if j == 0 else r_bull_probs\n",
    "        _val = (\n",
    "            np.log(_probs[realized_returns[tp1]]) + \n",
    "            np.log(betas[tp1, j])\n",
    "        )\n",
    "\n",
    "        value_bear += np.exp(_val + np.log(mc.P[0, j]))\n",
    "        value_bull += np.exp(_val + np.log(mc.P[1, j]))\n",
    "\n",
    "    betas[tp1-1, 0] = value_bear\n",
    "    betas[tp1-1, 1] = value_bull\n",
    "\n",
    "smoothing_probs = alphas*betas / np.sum(alphas*betas, axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae9a29",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How do these differ from the filtering probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93abc8e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Make cool graphs\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.scatter(tvalues, bb_idx, color=\"k\", alpha=0.5)\n",
    "ax.annotate(\"Bull Market\", (2, 1.05), color=\"k\")\n",
    "ax.annotate(\"Bear Market\", (2, -0.05), color=\"k\")\n",
    "\n",
    "ax.scatter(tvalues, (1 + realized_returns)/4, color=\"DarkBlue\", alpha=0.25)\n",
    "ax.annotate(\"Positive Return\", (99, 0.8), color=\"DarkBlue\")\n",
    "ax.annotate(\"Zero Return\", (99, 0.55), color=\"DarkBlue\")\n",
    "ax.annotate(\"Negative Return\", (99, 0.3), color=\"DarkBlue\")\n",
    "\n",
    "ax.plot(\n",
    "    tvalues, filtering_probs[:, 1], color=\"DarkOrange\",\n",
    "    alpha=0.7, linestyle=\"--\"\n",
    ")\n",
    "ax.annotate(\"Filtered Probabilities\", (95, 0.9), color=\"DarkOrange\")\n",
    "ax.plot(\n",
    "    tvalues, smoothing_probs[:, 1], color=\"DarkGreen\",\n",
    "    alpha=0.7, linestyle=\"--\"\n",
    ")\n",
    "ax.annotate(\"Smoothed Probabilities\", (95, 0.4), color=\"DarkGreen\")\n",
    "\n",
    "ax.set_xlim((0, 110))\n",
    "ax.set_ylim((-0.1, 1.1))\n",
    "\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97c5ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Prediction\n",
    "\n",
    "We might be interested in predicting the hidden state or observations in the future.\n",
    "\n",
    "For now, we'll focus on the one-step prediction, but it can be generalized.\n",
    "\n",
    "**Predicting the hidden state**\n",
    "\n",
    "The one-step prediction probability would be $P(x_{t+1} | y^t)$\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x_{t+1} | y^t) &= \\sum_{x_t} P(x_{t+1}, x_{t} | y^t) \\\\\n",
    "  &= \\sum_{x_t} P(x_{t+1} | x_{t}, y^t) P(x_{t} | y^t) \\\\\n",
    "  &= \\sum_{x_t} P(x_{t+1} | x_{t}) P(x_{t} | y^t) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "**Predicting the observation**\n",
    "\n",
    "The one-step prediction probability would be $P(y_{t+1} | y^t)$\n",
    "\n",
    "\\begin{align*}\n",
    "  P(y_{t+1} | y^t) &= \\sum_{x_t} \\sum_{x_{t+1}} P(y_{t+1}, x_{t+1}, x_{t} | y^t) \\\\\n",
    "  &= \\sum_{x_t} \\sum_{x_{t+1}} P(y_{t+1} | y^t, x_{t+1}, x_{t}) P(x_{t+1}, x_{t} | y^t) \\\\\n",
    "  &= \\sum_{x_t} \\sum_{x_{t+1}} P(y_{t+1} | x_{t+1}) P(x_{t+1}, x_{t} | y^t) \\\\\n",
    "  &= \\sum_{x_t} \\sum_{x_{t+1}} P(y_{t+1} | x_{t+1}) P(x_{t+1} | x_{t}) \\underbrace{P(x_t | y^t)}_{\\text{filtering probability}} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8c85e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Likelihood\n",
    "\n",
    "The likelihood probabilities are specified by\n",
    "\n",
    "\\begin{align*}\n",
    "  P(y^T) &= \\sum_{x_T} P(x_T, y^T) \\\\\n",
    "  &= \\sum_{x_T} \\alpha(x_T)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d20bee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Forward filter backward sample**\n",
    "\n",
    "If we want to draw sample paths from our sequence, we can do a \"forward filter backward sample\" procedure:\n",
    "\n",
    "We want to draw a sample from $P(x^T | y^T)$\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x^T | y^T) &= P(x_0 | x^{1:T}, y^T) P(x^{1:T} | y^T) \\\\\n",
    "  &= P(x_0 | x^{1:T}, y^T) P(x_1 | x^{2:T}, y^T) P(x^{2:T} | y^T) \\\\\n",
    "  &= P(x_0 | x^{1:T}, y^T) P(x_1 | x^{2:T}, y^T) \\dots P(x_T | y^T) \\\\\n",
    "  &= P(x_0 | x_1, y^T) P(x_1 | x_2, y^T) \\dots P(x_T | y^T)\n",
    "\\end{align*}\n",
    "\n",
    "Now, note that we can sample from $P(x_T | y^T)$ -- It is just the filtered probability at period $T$.\n",
    "\n",
    "Then for any $t$, we have $P(x_t | x_{t+1}, y^T)$:\n",
    "\n",
    "\\begin{align*}\n",
    "  P(x_t | x_{t+1}, y^T) &= \\frac{P(x_t, x_{t+1} | y^T)}{P(x_{t+1} | y^T)} \\\\\n",
    "  &=  \\frac{P(x_{t+1} | x_t, y^t) P(x_t | y^T)}{P(x_{t+1} | y^T)} \\\\\n",
    "  &\\propto P(x_{t+1} | x_t) \\beta(x_t)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e3368",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Most likely hidden state sequence**\n",
    "\n",
    "In addition to knowing the probabilities and being able to sample from our hidden states, we might be interested in what is the most likely sequence of hidden states that could have generated our data.\n",
    "\n",
    "This would be the solution to\n",
    "\n",
    "\\begin{align*}\n",
    "  \\max_{x^T} P(x^T | y^T) &\\propto \\max_{x^{T}} P(x^T, y^T) \\\\\n",
    "  &= \\max_{x^T} P(y_T | x_T, x^{T-1}, y^{T-1}) P(x_T, x^{T-1}, y^{T-1}) \\\\\n",
    "  &= \\max_{x^T} P(y_T | x_T) P(x_T | x^{T-1}, y^{T-1}) P(x^{T-1}, y^{T-1}) \\\\\n",
    "  &= \\max_{x^T} P(y_T | x_T) P(x_T | x_{T-1}) P(x^{T-1}, y^{T-1}) \\\\\n",
    "  &= \\dots \\\\\n",
    "  &= \\max_{x^T} \\prod_{t=0}^T P(y_t | x_t) P(x_t | x_{t-1}) \\\\\n",
    "  &= \\max_{x^{T-1}} \\left( \\prod_{t=0}^{T-1} P(y_t | x_t) P(x_t | x_{t-1}) \\right) \\max_{x_T} P(y_T | x_T) P(x_T | x_{T-1}) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Let\n",
    "\n",
    "\\begin{align*}\n",
    "  \\mu(x_{t-1}) &= \\max P(y_t | x_t) P(x_t | x_{t-1}) \\mu(x_{t})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091e25c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Does this look familiar yet? What if we take logs and write\n",
    "\n",
    "\\begin{align*}\n",
    "  \\log(\\mu(x^{t-1})) = \\max_{x_t} \\log(P(y_t | x_t)) + \\log(P(x_{t} | x_{t-1})) + \\log(\\mu(x_t))\n",
    "\\end{align*}\n",
    "\n",
    "Wait! This does look familiar - This is very similar to the \"minimum distance problem\" we discussed in the dynamic programming section!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80469b33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The solution in this context is referred to as the Viterbi algorithm and it is very similar to value function iteration -- We will compute the $\\{\\mu(x_t)\\}$ values first and then sequentially maximize our \"Bellman equation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c738007",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Building a class to automate the \"hard\" work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8dc7d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class HMMBB(object):\n",
    "    \"\"\"\n",
    "    Class to make it easy to compare various parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, p_bear, p_bull, r_bear_probs, r_bull_probs):\n",
    "        # Build Markov chain for hidden state\n",
    "        self.P = np.array([[p_bear, 1 - p_bear], [1 - p_bull, p_bull]])\n",
    "        self.mc = qe.MarkovChain(self.P)\n",
    "\n",
    "        # Build \"emission probabilities\"\n",
    "        self.emp = np.row_stack([r_bear_probs, r_bull_probs])\n",
    "\n",
    "    def simulate(self, T):\n",
    "        # First simulate the bear/bull component\n",
    "        bb_idx = self.mc.simulate_indices(T)\n",
    "\n",
    "        realized_returns = np.zeros(T, dtype=int)\n",
    "        for t, bb in enumerate(bb_idx):\n",
    "            # Build the discrete random variable of emission\n",
    "            # probabilities for each period\n",
    "            r_probs = qe.DiscreteRV(self.emp[bb, :])\n",
    "\n",
    "            # Draw random returns for period t\n",
    "            realized_returns[t] = r_probs.draw()[0]\n",
    "\n",
    "        return bb_idx, realized_returns\n",
    "\n",
    "    def forward(self, realized_returns):\n",
    "        \"\"\"\n",
    "        Computes \\alpha(x_t) := P(x_t, y^t)\n",
    "        \"\"\"\n",
    "        T = realized_returns.size\n",
    "        alphas = np.zeros((T, 2))\n",
    "\n",
    "        # Solve for period 0 -- Equal probability of starting\n",
    "        # in bear/bull market\n",
    "        alphas[0, 0] = self.emp[0, :][realized_returns[0]] * 0.5\n",
    "        alphas[0, 1] = self.emp[1, :][realized_returns[0]] * 0.5\n",
    "\n",
    "        for t in range(1, T):\n",
    "            # Sum over  x_{t-1}\n",
    "            predictor_bear = 0.0\n",
    "            predictor_bull = 0.0\n",
    "            for j in range(2):\n",
    "                #            alpha(x_{t-1}) P(x_t | x_{t-1})\n",
    "                predictor_bear += alphas[t-1, j]*self.P[j, 0]\n",
    "                predictor_bull += alphas[t-1, j]*self.P[j, 1]\n",
    "\n",
    "            alphas[t, 0] = self.emp[0, :][realized_returns[t]]*predictor_bear\n",
    "            alphas[t, 1] = self.emp[1, :][realized_returns[t]]*predictor_bull\n",
    "\n",
    "        return alphas\n",
    "\n",
    "    def filter_probabilities(self, alphas):\n",
    "        \"\"\"\n",
    "        Normalizes the alpha(x_t) values to compute\n",
    "        the filtered probabilites\n",
    "        \n",
    "        P(x_t | y^t)\n",
    "        \"\"\"\n",
    "        return alphas / np.sum(alphas, axis=1)[:, None]\n",
    "\n",
    "    def backward(self, realized_returns):\n",
    "        \"\"\"\n",
    "        Computes \\beta(x_t) := P(y^{t+1:T} | x_t)\n",
    "        \"\"\"\n",
    "        # Allocate memory for our alphas\n",
    "        T = realized_returns.size\n",
    "        betas = np.zeros((T, 2))\n",
    "\n",
    "        # Solve for period T -- This is just defined as 1\n",
    "        betas[-1, 0] = 1\n",
    "        betas[-1, 1] = 1\n",
    "        for tp1 in range(T-1, 0, -1):\n",
    "\n",
    "            # Sum over  x_{t-1} (exponent of sum is product of exponents)\n",
    "            value_bear = 0.0\n",
    "            value_bull = 0.0\n",
    "            for j in range(2):\n",
    "                _probs = self.emp[j, :]\n",
    "                _val = (\n",
    "                    np.log(_probs[realized_returns[tp1]]) + \n",
    "                    np.log(betas[tp1, j])\n",
    "                )\n",
    "\n",
    "                value_bear += np.exp(_val + np.log(self.P[0, j]))\n",
    "                value_bull += np.exp(_val + np.log(self.P[1, j]))\n",
    "\n",
    "            betas[tp1-1, 0] = value_bear\n",
    "            betas[tp1-1, 1] = value_bull\n",
    "\n",
    "        return betas\n",
    "\n",
    "    def smooth_probabilities(self, alphas, betas):\n",
    "        \"\"\"\n",
    "        Uses alpha(x_t) and beta(x_t) to compute the\n",
    "        smoothed probabilities\n",
    "        \n",
    "        P(x_t | y^T)\n",
    "        \"\"\"\n",
    "        return alphas*betas / np.sum(alphas*betas, axis=1)[:, None]\n",
    "\n",
    "    def ffbs(self, realized_returns):\n",
    "        # Allocate memory for output\n",
    "        T = realized_returns.size\n",
    "        x_sample = np.zeros(T, dtype=int)\n",
    "\n",
    "        # Compute forward probabilities and filtered probabilities\n",
    "        alphas = self.forward(realized_returns)\n",
    "        betas = self.backward(realized_returns)\n",
    "        filtered_probabilities = self.filter_probabilities(alphas)\n",
    "\n",
    "        # Now sample going backwards\n",
    "        sample_probs = filtered_probabilities[-1, :]\n",
    "        for t in range(T-1, -1, -1):\n",
    "            # Sample from current probabilities\n",
    "            rv = qe.DiscreteRV(sample_probs)\n",
    "            x_sample[t] = rv.draw()\n",
    "\n",
    "            # Update sampling probabilities\n",
    "            if t-1 > 0:\n",
    "                sample_probs = self.P[:, x_sample[t]]*betas[t-1, :]\n",
    "                sample_probs = sample_probs / sample_probs.sum()\n",
    "\n",
    "        return x_sample\n",
    "\n",
    "    def viterbi(self, realized_returns):\n",
    "        # Allocate memory for the mus\n",
    "        T = realized_returns.shape[0]\n",
    "        log_mus = np.ones((T, 2))\n",
    "\n",
    "        # Compute log mu values (use log for stability)\n",
    "        for t in range(T-1, 0, -1):\n",
    "            # Set mu value for each possible hidden state\n",
    "            for xtm1 in range(2):\n",
    "                # Take max over xts to fill in mu\n",
    "                possible_values = []\n",
    "                for xt in range(2):\n",
    "                    possible_values.append(\n",
    "                        np.log(self.emp[xt, realized_returns[t]]) +\n",
    "                        np.log(self.P[xtm1, xt]) + \n",
    "                        log_mus[t, xt]\n",
    "                    )\n",
    "\n",
    "                log_mus[t-1, xtm1] = max(possible_values)\n",
    "\n",
    "        xt_star = np.zeros(T, dtype=int)\n",
    "        xt_star[0] = np.argmax(\n",
    "            np.log(self.emp[:, realized_returns[0]]) +\n",
    "            np.log(0.5) +\n",
    "            log_mus[0, :]\n",
    "        )\n",
    "        for t in range(T):\n",
    "            xt_star[t] = np.argmax(\n",
    "                np.log(self.emp[:, realized_returns[t]]) +\n",
    "                np.log(self.P[xt_star[t-1], :]) +\n",
    "                log_mus[t, :]\n",
    "            )\n",
    "\n",
    "        return xt_star\n",
    "\n",
    "    def killer_graph(self, bb_idx, realized_returns):\n",
    "        # Size of data\n",
    "        T = bb_idx.shape[0]\n",
    "        tvalues = np.arange(T)\n",
    "\n",
    "        # Compute alpha, beta, filtered, and smoothed\n",
    "        alphas = self.forward(realized_returns)\n",
    "        betas = self.backward(realized_returns)\n",
    "        filtering_probs = self.filter_probabilities(alphas)\n",
    "        smoothing_probs = self.smooth_probabilities(alphas, betas)\n",
    "        \n",
    "        # Make cool graphs\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        ax.scatter(tvalues, bb_idx, color=\"k\", alpha=0.5)\n",
    "        ax.annotate(\"Bull Market\", (2, 1.05), color=\"k\")\n",
    "        ax.annotate(\"Bear Market\", (2, -0.05), color=\"k\")\n",
    "\n",
    "        ax.scatter(tvalues, (1 + realized_returns)/4, color=\"DarkBlue\", alpha=0.25)\n",
    "        ax.annotate(\"Positive Return\", (T-5, 0.8), color=\"DarkBlue\")\n",
    "        ax.annotate(\"Zero Return\", (T-5, 0.55), color=\"DarkBlue\")\n",
    "        ax.annotate(\"Negative Return\", (T-5, 0.3), color=\"DarkBlue\")\n",
    "\n",
    "        ax.plot(\n",
    "            tvalues, filtering_probs[:, 1], color=\"DarkOrange\",\n",
    "            alpha=0.7, linestyle=\"--\"\n",
    "        )\n",
    "        ax.annotate(\"Filtered Probabilities\", (T-10, 0.9), color=\"DarkOrange\")\n",
    "        ax.plot(\n",
    "            tvalues, smoothing_probs[:, 1], color=\"DarkGreen\",\n",
    "            alpha=0.7, linestyle=\"--\"\n",
    "        )\n",
    "        ax.annotate(\"Smoothed Probabilities\", (T-10, 0.4), color=\"DarkGreen\")\n",
    "\n",
    "        ax.set_xlim((0, 1.1*T))\n",
    "        ax.set_ylim((-0.1, 1.1))\n",
    "\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def killer_graph_2(self, bb_idx, realized_returns):\n",
    "        # Size of data\n",
    "        T = bb_idx.shape[0]\n",
    "        tvalues = np.arange(T)\n",
    "\n",
    "        # Compute n sample paths\n",
    "        n = 50\n",
    "        sample_paths = [self.ffbs(realized_returns) for i in range(n)]\n",
    "        most_likely = self.viterbi(realized_returns)\n",
    "        \n",
    "        # Make cool graphs\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        ax.scatter(tvalues, bb_idx, color=\"k\", alpha=0.5)\n",
    "        ax.annotate(\"Bull Market\", (2, 1.05), color=\"k\")\n",
    "        ax.annotate(\"Bear Market\", (2, -0.05), color=\"k\")\n",
    "\n",
    "        for i in range(n):\n",
    "            ax.plot(\n",
    "                tvalues, sample_paths[i]/3 + 1/3,\n",
    "                color=\"k\", alpha=0.1\n",
    "            )\n",
    "\n",
    "        ax.scatter(tvalues, most_likely/2 + 0.25, color=\"Green\")\n",
    "        ax.annotate(\"Viterbi Path\", (T, 0.75), color=\"Green\")\n",
    "\n",
    "        ax.set_xlim((0, 1.1*T))\n",
    "        ax.set_ylim((-0.1, 1.1))\n",
    "\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2da80f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_Filtering/smoothing probabilities and realized returns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb64139",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hmm = HMMBB(0.95, 0.95, np.array([0.7, 0.25, 0.05]), np.array([0.1, 0.3, 0.6]))\n",
    "\n",
    "bb_idx, realized_returns = hmm.simulate(156)\n",
    "hmm.killer_graph(bb_idx, realized_returns);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8d9f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "_Sample paths and Viterbi paths_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f585697",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hmm = HMMBB(0.9, 0.9, np.array([0.75, 0.2, 0.05]), np.array([0.1, 0.3, 0.6]))\n",
    "\n",
    "bb_idx, realized_returns = hmm.simulate(156)\n",
    "hmm.killer_graph_2(bb_idx, realized_returns);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d08e85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating a HMM!\n",
    "\n",
    "Up until this point, we've assumed a particular set of parameters.\n",
    "\n",
    "Is it possible to find the parameters of a HMM? Yes!\n",
    "\n",
    "We use an algorithm known as the Baum-Welch algorithm -- It is a special case of a set of algorithms called EM algorithms (expectation maximization algorithms).\n",
    "\n",
    "Roughly the way it works is:\n",
    "\n",
    "1. Guess parameter values\n",
    "2. Compute the $\\alpha$ and $\\beta$ probabilities (Expectation)\n",
    "3. Use these probabilities to update parameter values (Maximization)\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c8c028",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### More formally...\n",
    "\n",
    "**Step 1**\n",
    "\n",
    "We can guess any set of parameters that we'd like, but it often makes sense to use whatever information you might have...\n",
    "\n",
    "In our case,\n",
    "\n",
    "* we might reflect our belief that the bear/bull markets are at least somewhat persistent by guessing $p_{\\text{bear}} = 0.7$ and $p_{\\text{bull}} = 0.7$\n",
    "* we would also reflect this in our guesses of emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283729a3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p_bear_0 = 0.7\n",
    "p_bull_1 = 0.7\n",
    "\n",
    "emp_0 = np.array([[0.6, 0.3, 0.1], [0.1, 0.3, 0.6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e78d6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Step 2**\n",
    "\n",
    "Compute the forward ($\\alpha$) and backward ($\\beta$) probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e81e72",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "\n",
    "Use these probabilities to update our beliefs about the parameters. Let,\n",
    "\n",
    "* $\\gamma_i(t) \\equiv P(x_t | y^T, \\theta) = \\frac{\\alpha \\beta}{\\sum \\alpha \\beta}$ (smooth probabilities)\n",
    "* $\\xi_{ij} \\equiv P(x_t=i, x_{t+1}=j | y^T, \\theta) = \\frac{\\alpha(x_t) \\beta(x_{t+1}) P(x_{t+1} | x_t) P(y_{t+1} | x_{t+1})}{\\sum_{k=0}^1 \\sum_{w=0}^1 \\alpha(x_t=k) P(x_{t+1}=w | x_t=k) \\beta(x_{t+1}=w) P(y_{t+1} | x_{t+1}=w)}$\n",
    "\n",
    "then\n",
    "\n",
    "* $p_{\\text{bear}} = \\frac{\\sum_{t=0}^{T-1} \\xi_{00}(t)}{\\sum_{t=0}^{T-1}}$ (number of transitions from 0 to 0 )\n",
    "* $p_{\\text{bull}} = \\frac{\\sum_{t=0}^{T-1} \\xi_{11}(t)}{\\sum_{t=0}^{T-1}}$ (number of transitions from 1 to 1 )\n",
    "* $b_i(k) = \\frac{\\sum_{t=0}^T \\mathbb{1}_{y_t = k} \\gamma_i(t)}{\\sum_{t=0}^T \\gamma_i(t)}$ (fraction of time state $i$ generated observation $k$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf85fe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import hmmlearn.hmm as hml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0c660",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hmm = HMMBB(0.8, 0.8, np.array([0.75, 0.2, 0.05]), np.array([0.1, 0.3, 0.6]))\n",
    "bb_idx, realized_returns = hmm.simulate(5000)\n",
    "\n",
    "hmm_res = hml.MultinomialHMM(n_components=3).fit(realized_returns[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048f81d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Transition probabilities\")\n",
    "print(f\"\\tModel: {hmm.P}\")\n",
    "print(f\"\\tEstimate: {hmm_res.transmat_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f11bc2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Emission probabilities\")\n",
    "print(f\"\\tModel: {hmm.emp}\")\n",
    "print(f\"\\tEstimate: {hmm_res.emissionprob_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7de2ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Useful References**\n",
    "\n",
    "* [Blog post by Jonathan Hui](https://jonathan-hui.medium.com/machine-learning-hidden-markov-model-hmm-31660d217a61)\n",
    "* [Slides by Martin Haugh @ Columbia](http://www.columbia.edu/~mh2078/MachineLearningORFE/HMMs_MasterSlides.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
